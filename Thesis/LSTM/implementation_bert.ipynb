{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, Conv1D, GlobalMaxPooling1D, Concatenate, AdditiveAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from utils import eval, eval_training, get_train_test_data, save_for_evaluation, process_train_test_data\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '10'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '10'\n",
    "\n",
    "# Configure TensorFlow session for multi-threading\n",
    "tf.config.threading.set_inter_op_parallelism_threads(10)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(10)\n",
    "# Ensure TensorFlow is using the Metal backend\n",
    "gpu = len (tf.config.list_physical_devices ('GPU'))>0\n",
    "print (\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = \"data\"\n",
    "predict_label = \"label\"\n",
    "balanced = False\n",
    "labels = None\n",
    "class_weights = False\n",
    "sample_weights = False\n",
    "df_train = pd.read_csv('../data/data_train.csv')\n",
    "df_valid = pd.read_csv('../data/data_valid.csv')\n",
    "df_test = pd.read_csv('../data/data_test.csv')\n",
    "\n",
    "train_texts = df_train[data_label]\n",
    "valid_texts = df_valid[data_label]\n",
    "test_texts = df_test[data_label]\n",
    "\n",
    "all_labels = pd.concat([df_train[predict_label], df_valid[predict_label], df_test[predict_label]])\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "# Fit label encoder and return encoded labels as integers\n",
    "train_labels_enc = label_encoder.transform(df_train[predict_label])\n",
    "valid_labels_enc = label_encoder.transform(df_valid[predict_label])\n",
    "test_labels_enc = label_encoder.transform(df_test[predict_label])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "train_labels = to_categorical(train_labels_enc)\n",
    "valid_labels = to_categorical(valid_labels_enc)\n",
    "test_labels = to_categorical(test_labels_enc)\n",
    "\n",
    "num_classes = len(df_train[predict_label].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import concurrent.futures\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate word embeddings for a given batch of texts\n",
    "def generate_bert_embeddings_batch(texts, tokenizer, model, max_length):\n",
    "    inputs = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings.numpy()\n",
    "\n",
    "model_name = \"GerMedBERT/medbert-512\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate embeddings concurrently in batches\n",
    "def generate_embeddings_concurrently(texts, tokenizer, model, max_length, batch_size=32):\n",
    "    embeddings = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            futures.append(executor.submit(generate_bert_embeddings_batch, batch_texts, tokenizer, model, max_length))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                batch_embeddings = future.result()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "            except Exception as exc:\n",
    "                print(f'Generated an exception: {exc}')\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Ensure texts are in list format\n",
    "train_texts = train_texts.tolist()\n",
    "valid_texts = valid_texts.tolist()\n",
    "test_texts = test_texts.tolist()\n",
    "\n",
    "# Define the max length for padding\n",
    "max_length = 400  # or set to a specific value based on your data\n",
    "print(\"Starting\")\n",
    "\n",
    "# Generate embeddings concurrently in batches\n",
    "bert_train_embeddings = generate_embeddings_concurrently(train_texts, tokenizer, model, max_length)\n",
    "bert_padded_train_embeddings = np.pad(bert_train_embeddings, ((0,0),(0,max_length-bert_train_embeddings.shape[1]),(0,0)), 'constant')\n",
    "# Save padded embeddings to files\n",
    "with open('bert_train.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_padded_train_embeddings, file)\n",
    "print(\"Training done\")\n",
    "\n",
    "bert_valid_embeddings = generate_embeddings_concurrently(valid_texts, tokenizer, model, max_length)\n",
    "bert_padded_valid_embeddings = np.pad(bert_valid_embeddings, ((0,0),(0,max_length-bert_valid_embeddings.shape[1]),(0,0)), 'constant')\n",
    "with open('bert_valid.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_padded_valid_embeddings, file)\n",
    "print(\"Valid done\")\n",
    "\n",
    "bert_test_embeddings = generate_embeddings_concurrently(test_texts, tokenizer, model, max_length)\n",
    "bert_padded_test_embeddings = np.pad(bert_test_embeddings, ((0,0),(0,max_length-bert_test_embeddings.shape[1]),(0,0)), 'constant')\n",
    "with open('bert_test.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_padded_test_embeddings, file)\n",
    "print(\"Test done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"bert_train.pkl\", \"rb\") as input_file:\n",
    "    bert_padded_train_embeddings = pickle.load(input_file)\n",
    "with open(\"bert_valid.pkl\", \"rb\") as input_file:\n",
    "    bert_padded_valid_embeddings = pickle.load(input_file)\n",
    "with open(\"bert_test.pkl\", \"rb\") as input_file:\n",
    "    bert_padded_test_embeddings = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = bert_padded_train_embeddings.shape[-1]\n",
    "max_length = 400\n",
    "model_name = \"bert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_standard_parameters\n",
    "\n",
    "optimizer, loss, metrics, early_stopping_callback, _, lstm_units, epochs, batch_size = get_standard_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layers\n",
    "input_text = Input(shape=(max_length, embedding_dim), dtype='float32', name='text_input')\n",
    "\n",
    "# Two LSTM layers\n",
    "x = Bidirectional(LSTM(units=lstm_units, return_sequences=True))(input_text)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(units=lstm_units))(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(bert_padded_train_embeddings, train_labels, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(bert_padded_valid_embeddings, valid_labels), callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_for_evaluation(model, history, model_name, test_padded, test_labels, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_training(history, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(model, test_padded, test_labels, label_encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
