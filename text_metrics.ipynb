{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.0/en_core_sci_sm-0.2.0.tar.gz\n",
      "  Using cached https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.0/en_core_sci_sm-0.2.0.tar.gz (15.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting spacy>=2.1.3 (from en_core_sci_sm==0.2.0)\n",
      "  Downloading spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading murmurhash-1.0.10-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading cymem-2.0.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading srsly-2.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from spacy>=2.1.3->en_core_sci_sm==0.2.0) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from spacy>=2.1.3->en_core_sci_sm==0.2.0) (2.32.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from spacy>=2.1.3->en_core_sci_sm==0.2.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from spacy>=2.1.3->en_core_sci_sm==0.2.0) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from spacy>=2.1.3->en_core_sci_sm==0.2.0) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached langcodes-3.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from spacy>=2.1.3->en_core_sci_sm==0.2.0) (1.26.4)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading pydantic_core-2.20.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.1.3->en_core_sci_sm==0.2.0) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->en_core_sci_sm==0.2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->en_core_sci_sm==0.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->en_core_sci_sm==0.2.0) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.1.3->en_core_sci_sm==0.2.0) (2024.7.4)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0.0,>=0.3.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached cloudpathlib-0.18.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from jinja2->spacy>=2.1.3->en_core_sci_sm==0.2.0) (2.1.5)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading marisa_trie-1.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.3->en_core_sci_sm==0.2.0) (2.18.0)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.1.3->en_core_sci_sm==0.2.0)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl (6.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp312-cp312-macosx_11_0_arm64.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached langcodes-3.4.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.10-cp312-cp312-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Downloading pydantic_core-2.20.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp312-cp312-macosx_11_0_arm64.whl (486 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.4/486.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.6/760.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached cloudpathlib-0.18.1-py3-none-any.whl (47 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.0-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.6/173.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: en_core_sci_sm\n",
      "  Building wheel for en_core_sci_sm (setup.py): started\n",
      "  Building wheel for en_core_sci_sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en_core_sci_sm: filename=en_core_sci_sm-0.2.0-py3-none-any.whl size=15065453 sha256=7e80001cbe9085f3c7265907046a75b9bdf70647ee66c1ccbe839787a0fee016\n",
      "  Stored in directory: /Users/aleksandratopalova/Library/Caches/pip/wheels/67/82/7c/8b11dfb78e36bcd7fe867490358a5f8a57d179a3df18e2bf2f\n",
      "Successfully built en_core_sci_sm\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, pydantic-core, murmurhash, mdurl, marisa-trie, cloudpathlib, click, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy, en_core_sci_sm\n",
      "Successfully installed annotated-types-0.7.0 blis-0.7.11 catalogue-2.0.10 click-8.1.7 cloudpathlib-0.18.1 confection-0.1.5 cymem-2.0.8 en_core_sci_sm-0.2.0 langcodes-3.4.0 language-data-1.2.0 marisa-trie-1.2.0 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.8.2 pydantic-core-2.20.1 rich-13.7.1 shellingham-1.5.4 smart-open-7.0.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.12.3 wasabi-1.1.3 weasel-0.4.1 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.0/en_core_sci_sm-0.2.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scispacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load spacy model for medical terminology extraction\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_core_sci_sm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize stopwords\u001b[39;00m\n\u001b[1;32m     14\u001b[0m stop_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages/spacy/util.py:465\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_lang_class(name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblank:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))()\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_package(name):  \u001b[38;5;66;03m# installed as package\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_model_from_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(name)\u001b[38;5;241m.\u001b[39mexists():  \u001b[38;5;66;03m# path to model data directory\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages/spacy/util.py:500\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model_from_package\u001b[39m(\n\u001b[1;32m    476\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    482\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m SimpleFrozenDict(),\n\u001b[1;32m    483\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    name (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mload(vocab\u001b[38;5;241m=\u001b[39mvocab, disable\u001b[38;5;241m=\u001b[39mdisable, enable\u001b[38;5;241m=\u001b[39menable, exclude\u001b[38;5;241m=\u001b[39mexclude, config\u001b[38;5;241m=\u001b[39mconfig)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/torch_no_mps/lib/python3.12/site-packages/en_core_sci_sm/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Language\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model_from_init_py, get_model_meta\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscispacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_sentence_segmenter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combined_rule_sentence_segmenter\n\u001b[1;32m      9\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m get_model_meta(Path(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moverrides):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scispacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import textstat\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Load spacy model for medical terminology extraction\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "\n",
    "# Initialize stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Lists to store results\n",
    "cosine_similarities = []\n",
    "medical_terms_counts = []\n",
    "readability_metrics = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Create an array of tuples from the \"questionnaire\" and \"data\" columns\n",
    "tuple_array = list(zip(df['questionnaire'], df['data']))\n",
    "\n",
    "# Display the result\n",
    "print(tuple_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_prediction_list = [\n",
    "    (\n",
    "        '37.0 After rising from a deep squat Slight twisting goes better Two years ago, inner ligament strain in the left knee When stretching, pressing certain points on the inner side Feeling of blockage, limited extension Bending almost fully possible, extension very limited Inner ligament strain about 2 years ago', \n",
    "        '37.0 years old On 5.8.24, sudden shooting pain in the left knee joint while rising from a squat, followed by inability to straighten the knee and joint swelling, two years ago inner ligament strain and popping in the knee during joint extension, then symptom-free, sports triathlon and running. My left knee joint has no hyperextension, but a deficit in extension. Knee bending is good. My knee joint has slight swelling. I feel stable and there is pain on the inner side of the knee joint.'\n",
    "    ),\n",
    "    (\n",
    "        '62.0 Male I felt a cracking sound when standing up from a deep squat No, only standing up from a deep squat Suddenly four weeks ago Slight swelling and inability to straighten the knee Can’t straighten, bending almost not affected', \n",
    "        '62.0 years old Pain for 3 days in the left knee joint. I cannot hyperextend my knee, but there is no extension deficit and bending is well possible. My knee is not swollen.'\n",
    "    ),\n",
    "    (\n",
    "        '62.0 Male During a handball game, I feigned a strike to the right and wanted to run past the opponent on the left. Then there was a cracking sound in the knee joint, and somehow my knee gave way. Yes, my knee gave way and it cracked Severe pain in the knee at first, but after a few days, it has gotten much better. At the moment, the knee is slightly swollen, and I can’t move it properly, neither stretching nor bending I can’t straighten the knee at the moment and can’t fully bend it I’ve never had an injury to the right knee joint before.', \n",
    "        '62.0 years old Pain for 3 days in the left knee joint. I cannot hyperextend my knee, but there is no extension deficit and bending is well possible. My knee is not swollen.'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import textstat\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Lists to store results\n",
    "results = []\n",
    "\n",
    "# Process each pair in diag_prediction_list\n",
    "for (X, Y) in diag_prediction_list:\n",
    "    # Tokenize and remove stopwords\n",
    "    X_list = [word for word in word_tokenize(X.lower()) if word.isalpha() and word not in stop_words]\n",
    "    Y_list = [word for word in word_tokenize(Y.lower()) if word.isalpha() and word not in stop_words]\n",
    "    \n",
    "    # Create word frequency vectors\n",
    "    X_vector = Counter(X_list)\n",
    "    Y_vector = Counter(Y_list)\n",
    "    \n",
    "    # Convert to vectors for cosine similarity\n",
    "    words = list(set(X_list + Y_list))\n",
    "    X_freq_vector = [X_vector.get(word, 0) for word in words]\n",
    "    Y_freq_vector = [Y_vector.get(word, 0) for word in words]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    cos_sim = cosine_similarity([X_freq_vector], [Y_freq_vector])[0][0]\n",
    "    \n",
    "    # Compute readability scores\n",
    "    X_readability = {\n",
    "        'flesch_kincaid_grade': textstat.flesch_kincaid_grade(X),\n",
    "        'flesch_reading_ease': textstat.flesch_reading_ease(X),\n",
    "        'gunning_fog_index': textstat.gunning_fog(X)\n",
    "    }\n",
    "    Y_readability = {\n",
    "        'flesch_kincaid_grade': textstat.flesch_kincaid_grade(Y),\n",
    "        'flesch_reading_ease': textstat.flesch_reading_ease(Y),\n",
    "        'gunning_fog_index': textstat.gunning_fog(Y)\n",
    "    }\n",
    "    \n",
    "    # Append results to list\n",
    "    results.append({\n",
    "        'Sentence 1': X,\n",
    "        'Sentence 2': Y,\n",
    "        'Cosine Similarity (%)': cos_sim * 100,\n",
    "        'Flesch Reading Ease 1': X_readability['flesch_reading_ease'],\n",
    "        'Flesch Reading Ease 2': Y_readability['flesch_reading_ease']\n",
    "    })\n",
    "\n",
    "# Create DataFrame from results\n",
    "df = pd.DataFrame(results).round(2)\n",
    "\n",
    "# Save DataFrame as CSV\n",
    "df.to_csv('sentence_metrics.csv', index=False)\n",
    "\n",
    "print(\"Metrics saved to CSV file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
