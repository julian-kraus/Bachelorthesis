{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:52:46.500729Z",
     "start_time": "2024-07-22T17:52:46.492058Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Bidirectional, Conv1D, GlobalMaxPooling1D, Concatenate, AdditiveAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from utils import eval, eval_training, get_train_test_data\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '10'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '10'\n",
    "\n",
    "# Configure TensorFlow session for multi-threading\n",
    "tf.config.threading.set_inter_op_parallelism_threads(10)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(10)\n",
    "# Ensure TensorFlow is using the Metal backend\n",
    "gpu = len (tf.config.list_physical_devices ('GPU'))>0\n",
    "print (\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "bbce78941e041915",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:53:20.736542Z",
     "start_time": "2024-07-22T17:53:20.174700Z"
    }
   },
   "source": [
    "data_label = \"data\"\n",
    "predict_label = \"label\"\n",
    "balanced = False\n",
    "labels = [\"meniskus_urgent\", \"cruciate_urgent\"]\n",
    "class_weights = False\n",
    "sample_weights = False\n",
    "df = pd.read_csv('../data/balanced_classification_dataset.csv')\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "if labels is not None:\n",
    "  df = df[df['label'].isin(labels)]\n",
    "\n",
    "# Split data into training and temporary data (the remaining 40%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=42, stratify=df[predict_label])\n",
    "\n",
    "# Split the temporary data into validation and test sets (each 50% of temporary, thus 20% of total each)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[predict_label])\n",
    "\n",
    "# Check the size of each set\n",
    "print(\"Training set size:\", len(train_df))\n",
    "print(\"Validation set size:\", len(valid_df))\n",
    "print(\"Test set size:\", len(test_df))\n",
    "# Prepare data for training\n",
    "train_texts = train_df[data_label]\n",
    "valid_texts = valid_df[data_label]\n",
    "test_texts = test_df[data_label]\n",
    "\n",
    "# Initialize the label encoder\n",
    "all_labels = pd.concat([train_df[predict_label], valid_df[predict_label], test_df[predict_label]])\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_labels)\n",
    "# Fit label encoder and return encoded labels as integers\n",
    "train_labels_enc = label_encoder.transform(train_df[predict_label])\n",
    "valid_labels_enc = label_encoder.transform(valid_df[predict_label])\n",
    "test_labels_enc = label_encoder.transform(test_df[predict_label])\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "train_labels = to_categorical(train_labels_enc)\n",
    "valid_labels = to_categorical(valid_labels_enc)\n",
    "test_labels = to_categorical(test_labels_enc)\n",
    "\n",
    "num_classes = len(train_df[predict_label].unique())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 14946\n",
      "Validation set size: 4982\n",
      "Test set size: 4982\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "534ec3e56f51a347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:50:00.979393Z",
     "start_time": "2024-07-22T17:50:00.977405Z"
    }
   },
   "source": [
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 64\n",
    "epochs = 10\n",
    "batch_size = 32"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "1b4acdd9fdcece87",
   "metadata": {},
   "source": [
    "# No Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b45e19f8107774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T09:48:56.178787Z",
     "start_time": "2024-07-22T09:48:56.099586Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 11:48:56.102126: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2024-07-22 11:48:56.102153: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-07-22 11:48:56.102157: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-07-22 11:48:56.102170: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-22 11:48:56.102184: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "metrics=[\n",
    "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.F1Score(name='f1_score'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "id": "f74efd41ed49c687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:54:03.506063Z",
     "start_time": "2024-07-22T17:54:02.024749Z"
    }
   },
   "source": [
    "# Tokenize texts\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_texts)  # Only fit on train data\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "valid_sequences = tokenizer.texts_to_sequences(valid_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "max_length = max(len(sequence) for sequence in train_sequences) + 30\n",
    "print(max_length)\n",
    "# Padding sequences\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "valid_padded = pad_sequences(valid_sequences, maxlen=max_length, padding='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1b201b9f9a4afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:01:30.193904Z",
     "start_time": "2024-07-21T15:01:29.662480Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=len(word_index), output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = Bidirectional(LSTM(units=lstm_units, return_sequences=True))(embedding)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(units=lstm_units))(embedding)\n",
    "\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model_base = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model_base.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3d9836778cbb9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:09:18.439972Z",
     "start_time": "2024-07-21T15:01:30.194550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 17:01:30.511902: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m53s\u001B[0m 114ms/step - accuracy: 0.4673 - auc: 0.8264 - f1_score: 0.2134 - loss: 1.2916 - val_accuracy: 0.5768 - val_auc: 0.8809 - val_f1_score: 0.3012 - val_loss: 1.0893\n",
      "Epoch 2/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 111ms/step - accuracy: 0.6093 - auc: 0.8894 - f1_score: 0.3176 - loss: 1.0492 - val_accuracy: 0.5828 - val_auc: 0.8856 - val_f1_score: 0.3058 - val_loss: 1.0687\n",
      "Epoch 3/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 109ms/step - accuracy: 0.6710 - auc: 0.9115 - f1_score: 0.3510 - loss: 0.9337 - val_accuracy: 0.5919 - val_auc: 0.8881 - val_f1_score: 0.3085 - val_loss: 1.0558\n",
      "Epoch 4/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 108ms/step - accuracy: 0.7102 - auc: 0.9277 - f1_score: 0.3827 - loss: 0.8423 - val_accuracy: 0.5911 - val_auc: 0.8866 - val_f1_score: 0.3268 - val_loss: 1.0754\n",
      "Epoch 5/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 108ms/step - accuracy: 0.7514 - auc: 0.9427 - f1_score: 0.4462 - loss: 0.7437 - val_accuracy: 0.5881 - val_auc: 0.8817 - val_f1_score: 0.3276 - val_loss: 1.1244\n",
      "Epoch 6/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 109ms/step - accuracy: 0.7938 - auc: 0.9560 - f1_score: 0.4977 - loss: 0.6432 - val_accuracy: 0.5810 - val_auc: 0.8748 - val_f1_score: 0.3324 - val_loss: 1.1875\n",
      "Epoch 7/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 110ms/step - accuracy: 0.8135 - auc: 0.9642 - f1_score: 0.5477 - loss: 0.5779 - val_accuracy: 0.5794 - val_auc: 0.8675 - val_f1_score: 0.3405 - val_loss: 1.2584\n",
      "Epoch 8/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 107ms/step - accuracy: 0.8314 - auc: 0.9708 - f1_score: 0.5930 - loss: 0.5207 - val_accuracy: 0.5814 - val_auc: 0.8650 - val_f1_score: 0.3581 - val_loss: 1.3154\n",
      "Epoch 9/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 107ms/step - accuracy: 0.8589 - auc: 0.9774 - f1_score: 0.6515 - loss: 0.4532 - val_accuracy: 0.5688 - val_auc: 0.8581 - val_f1_score: 0.3518 - val_loss: 1.3908\n",
      "Epoch 10/10\n",
      "\u001B[1m425/425\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 107ms/step - accuracy: 0.8678 - auc: 0.9807 - f1_score: 0.6777 - loss: 0.4178 - val_accuracy: 0.5635 - val_auc: 0.8501 - val_f1_score: 0.3564 - val_loss: 1.4569\n"
     ]
    }
   ],
   "source": [
    "history_base = model_base.fit(train_padded, train_labels, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=(valid_padded, valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76817940e82536",
   "metadata": {},
   "source": [
    "# Word2Vec Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630e5d048c59a116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T18:53:31.667503Z",
     "start_time": "2024-07-21T18:53:31.653540Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "embedding_dim = 300\n",
    "metrics=[\n",
    "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.F1Score(average=\"macro\", name='f1_score'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86a280b2a154a02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T18:53:26.754976Z",
     "start_time": "2024-07-21T18:53:17.964138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-ZäöüÄÖÜß\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    stop_words = spacy.lang.de.stop_words.STOP_WORDS\n",
    "    words = [token.text for token in doc if token.text.lower() not in stop_words and token.is_alpha]\n",
    "    return words\n",
    "\n",
    "def get_word2vec_embeddings(text, model, vector_size=300):\n",
    "    tokens = preprocess_text(text)\n",
    "    embeddings = np.zeros((len(tokens), vector_size))\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in model.wv:\n",
    "            embeddings[i] = model.wv[token]\n",
    "        else:\n",
    "            embeddings[i] = np.zeros(vector_size)\n",
    "    return embeddings\n",
    "\n",
    "# Load pre-trained Word2Vec embeddings\n",
    "w2v = Word2Vec.load(\"../data/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e077ccd2272c16aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T19:02:29.784288Z",
     "start_time": "2024-07-21T18:53:39.082631Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m x \u001B[38;5;241m=\u001B[39m Bidirectional(LSTM(units\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, return_sequences\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))(input_text)\n\u001B[1;32m     15\u001B[0m x \u001B[38;5;241m=\u001B[39m Dropout(\u001B[38;5;241m0.5\u001B[39m)(x)\n\u001B[0;32m---> 16\u001B[0m x \u001B[38;5;241m=\u001B[39m Bidirectional(LSTM(units\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, return_sequences\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))(\u001B[43membedding\u001B[49m)\n\u001B[1;32m     17\u001B[0m x \u001B[38;5;241m=\u001B[39m Dropout(\u001B[38;5;241m0.5\u001B[39m)(x)\n\u001B[1;32m     18\u001B[0m x \u001B[38;5;241m=\u001B[39m Bidirectional(LSTM(units\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, return_sequences\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))(embedding)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'embedding' is not defined"
     ]
    }
   ],
   "source": [
    "w2v_train_embeddings = [get_word2vec_embeddings(text, w2v) for text in train_texts]\n",
    "w2v_valid_embeddings = [get_word2vec_embeddings(text, w2v) for text in valid_texts]\n",
    "w2v_test_embeddings = [get_word2vec_embeddings(text, w2v) for text in test_texts]\n",
    "max_length = max(len(embedding) for embedding in w2v_train_embeddings)\n",
    "w2v_padded_train_embeddings = pad_sequences(w2v_train_embeddings, maxlen=max_length, padding='post', dtype='float32')\n",
    "w2v_padded_valid_embeddings = pad_sequences(w2v_valid_embeddings, maxlen=max_length, padding='post', dtype='float32')\n",
    "w2v_padded_test_embeddings = pad_sequences(w2v_test_embeddings, maxlen=max_length, padding='post', dtype='float32')\n",
    "\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length, embedding_dim), dtype='float32', name='text_input')\n",
    "\n",
    "# Two LSTM layers\n",
    "x = Bidirectional(LSTM(units=lstm_units, return_sequences=True))(input_text)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(units=lstm_units))(embedding)\n",
    "\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model_word2vec = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model_word2vec.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6567abe87084c13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T19:44:06.874165Z",
     "start_time": "2024-07-21T19:03:26.370041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 21:03:31.992280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m253s\u001B[0m 290ms/step - accuracy: 0.3981 - auc: 0.7935 - f1_score: 0.1251 - loss: 1.3708 - val_accuracy: 0.4085 - val_auc: 0.8129 - val_f1_score: 0.1545 - val_loss: 1.3150\n",
      "Epoch 2/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m242s\u001B[0m 285ms/step - accuracy: 0.4007 - auc: 0.8069 - f1_score: 0.1287 - loss: 1.3239 - val_accuracy: 0.4075 - val_auc: 0.8172 - val_f1_score: 0.0966 - val_loss: 1.2927\n",
      "Epoch 3/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m243s\u001B[0m 286ms/step - accuracy: 0.4078 - auc: 0.8097 - f1_score: 0.1327 - loss: 1.3138 - val_accuracy: 0.3870 - val_auc: 0.8158 - val_f1_score: 0.1510 - val_loss: 1.2949\n",
      "Epoch 4/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m242s\u001B[0m 285ms/step - accuracy: 0.4166 - auc: 0.8161 - f1_score: 0.1651 - loss: 1.2945 - val_accuracy: 0.4555 - val_auc: 0.8387 - val_f1_score: 0.1920 - val_loss: 1.2226\n",
      "Epoch 5/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m242s\u001B[0m 285ms/step - accuracy: 0.4216 - auc: 0.8191 - f1_score: 0.1630 - loss: 1.2867 - val_accuracy: 0.4578 - val_auc: 0.8414 - val_f1_score: 0.1920 - val_loss: 1.2147\n",
      "Epoch 6/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m243s\u001B[0m 286ms/step - accuracy: 0.4222 - auc: 0.8193 - f1_score: 0.1667 - loss: 1.2859 - val_accuracy: 0.4546 - val_auc: 0.8424 - val_f1_score: 0.2069 - val_loss: 1.2160\n",
      "Epoch 7/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m243s\u001B[0m 286ms/step - accuracy: 0.4371 - auc: 0.8244 - f1_score: 0.1709 - loss: 1.2742 - val_accuracy: 0.4685 - val_auc: 0.8468 - val_f1_score: 0.2120 - val_loss: 1.2030\n",
      "Epoch 8/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m243s\u001B[0m 286ms/step - accuracy: 0.4346 - auc: 0.8245 - f1_score: 0.1869 - loss: 1.2720 - val_accuracy: 0.4795 - val_auc: 0.8434 - val_f1_score: 0.2374 - val_loss: 1.2302\n",
      "Epoch 9/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m242s\u001B[0m 285ms/step - accuracy: 0.4328 - auc: 0.8208 - f1_score: 0.1783 - loss: 1.2828 - val_accuracy: 0.4614 - val_auc: 0.8413 - val_f1_score: 0.2191 - val_loss: 1.2204\n",
      "Epoch 10/10\n",
      "\u001B[1m849/849\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m243s\u001B[0m 286ms/step - accuracy: 0.4317 - auc: 0.8215 - f1_score: 0.1759 - loss: 1.2822 - val_accuracy: 0.4551 - val_auc: 0.8433 - val_f1_score: 0.2188 - val_loss: 1.2083\n"
     ]
    }
   ],
   "source": [
    "history_word2vec = model_word2vec.fit(w2v_padded_train_embeddings, train_labels, \n",
    "                                      epochs=10, batch_size=32, \n",
    "                                      validation_data=(w2v_padded_valid_embeddings, valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5ff88ca032310b",
   "metadata": {},
   "source": [
    "# Bert Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "id": "2767be12e14abfd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:50:09.474545Z",
     "start_time": "2024-07-22T17:50:09.354823Z"
    }
   },
   "source": [
    "optimizer = Adam()\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "metrics=[\n",
    "      tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.F1Score(name='f1_score'),\n",
    "]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:50:09.361011: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2024-07-22 19:50:09.361049: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-07-22 19:50:09.361057: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-07-22 19:50:09.361084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-22 19:50:09.361099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35da1ebb-4442-4999-b648-c0af3bb7eb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Training done\n",
      "Valid done\n",
      "Test done\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import concurrent.futures\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate word embeddings for a given batch of texts\n",
    "def generate_bert_embeddings_batch(texts, tokenizer, model, max_length):\n",
    "    inputs = tokenizer(texts, truncation=True, padding='max_length', max_length=max_length, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings.numpy()\n",
    "\n",
    "model_name = \"GerMedBERT/medbert-512\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate embeddings concurrently in batches\n",
    "def generate_embeddings_concurrently(texts, tokenizer, model, max_length, batch_size=32):\n",
    "    embeddings = []\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            futures.append(executor.submit(generate_bert_embeddings_batch, batch_texts, tokenizer, model, max_length))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                batch_embeddings = future.result()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "            except Exception as exc:\n",
    "                print(f'Generated an exception: {exc}')\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Ensure texts are in list format\n",
    "train_texts = train_texts.tolist()\n",
    "valid_texts = valid_texts.tolist()\n",
    "test_texts = test_texts.tolist()\n",
    "\n",
    "# Define the max length for padding\n",
    "max_length = 400  # or set to a specific value based on your data\n",
    "print(\"Starting\")\n",
    "\n",
    "# Generate embeddings concurrently in batches\n",
    "bert_train_embeddings = generate_embeddings_concurrently(train_texts, tokenizer, model, max_length)\n",
    "bert_padded_train_embeddings = np.pad(bert_train_embeddings, ((0,0),(0,max_length-bert_train_embeddings.shape[1]),(0,0)), 'constant')\n",
    "# Save padded embeddings to files\n",
    "with open('bert_train.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_padded_train_embeddings, file)\n",
    "print(\"Training done\")\n",
    "\n",
    "bert_valid_embeddings = generate_embeddings_concurrently(valid_texts, tokenizer, model, max_length)\n",
    "bert_padded_valid_embeddings = np.pad(bert_valid_embeddings, ((0,0),(0,max_length-bert_valid_embeddings.shape[1]),(0,0)), 'constant')\n",
    "with open('bert_valid.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_padded_valid_embeddings, file)\n",
    "print(\"Valid done\")\n",
    "\n",
    "bert_test_embeddings = generate_embeddings_concurrently(test_texts, tokenizer, model, max_length)\n",
    "bert_padded_test_embeddings = np.pad(bert_test_embeddings, ((0,0),(0,max_length-bert_test_embeddings.shape[1]),(0,0)), 'constant')\n",
    "with open('bert_test.pkl', 'wb') as file:\n",
    "    pickle.dump(bert_padded_test_embeddings, file)\n",
    "print(\"Test done\")\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:52:35.330091Z",
     "start_time": "2024-07-22T17:52:27.501090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open(\"bert_train.pkl\", \"rb\") as input_file:\n",
    "    bert_padded_train_embeddings = pickle.load(input_file)\n",
    "with open(\"bert_valid.pkl\", \"rb\") as input_file:\n",
    "    bert_padded_valid_embeddings = pickle.load(input_file)\n",
    "with open(\"bert_test.pkl\", \"rb\") as input_file:\n",
    "    bert_padded_test_embeddings = pickle.load(input_file)"
   ],
   "id": "a9a7798acd836d7d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d203e09b8ebb4fb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:55:56.607626Z",
     "start_time": "2024-07-22T17:55:56.506788Z"
    }
   },
   "source": [
    "embedding_dim = bert_padded_train_embeddings.shape[-1]\n",
    "max_length = 400\n",
    "# Define the input layers\n",
    "input_text = Input(shape=(max_length, embedding_dim), dtype='float32', name='text_input')\n",
    "\n",
    "# Two LSTM layers\n",
    "x = Bidirectional(LSTM(units=lstm_units, return_sequences=True))(input_text)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(units=lstm_units))(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model_bert = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Define the model\n",
    "\n",
    "# Compile the model\n",
    "model_bert.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "dfb90b47380e0e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T18:00:09.692186Z",
     "start_time": "2024-07-22T17:55:57.259734Z"
    }
   },
   "source": [
    "history_bert = model_bert.fit(bert_padded_train_embeddings, train_labels, \n",
    "                                      epochs=10, batch_size=32, \n",
    "                                      validation_data=(bert_padded_valid_embeddings, valid_labels))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:56:56.973191: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m468/468\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m110s\u001B[0m 230ms/step - accuracy: 0.7369 - auc: 0.7446 - f1_score: 0.4403 - loss: 0.5835 - val_accuracy: 0.7403 - val_auc: 0.7348 - val_f1_score: 0.4254 - val_loss: 0.5737\n",
      "Epoch 2/10\n",
      "\u001B[1m468/468\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 163ms/step - accuracy: 0.7402 - auc: 0.7408 - f1_score: 0.4256 - loss: 0.5757"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history_bert \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_bert\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbert_padded_train_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbert_padded_valid_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:343\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_epoch_iterator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    333\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_epoch_iterator \u001B[38;5;241m=\u001B[39m TFEpochIterator(\n\u001B[1;32m    334\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m    335\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    341\u001B[0m         shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    342\u001B[0m     )\n\u001B[0;32m--> 343\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    355\u001B[0m }\n\u001B[1;32m    356\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:429\u001B[0m, in \u001B[0;36mTensorFlowTrainer.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    428\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m--> 429\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    430\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    431\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_end(step, logs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1552\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1555\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1556\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1560\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1561\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1562\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1566\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1567\u001B[0m   )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "1f402894d5f16c50",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61158811156cf4c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:37:16.915694Z",
     "start_time": "2024-07-21T15:37:16.915633Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_training(history_base, metrics)\n",
    "eval(model_base, test_padded, test_labels, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f19a3b7920202",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_training(history_word2vec, metrics)\n",
    "eval(model_word2vec, w2v_padded_test_embeddings, test_labels, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8af8f1ad931301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
