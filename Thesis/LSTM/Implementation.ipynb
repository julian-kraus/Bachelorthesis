{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T20:09:55.680136Z",
     "start_time": "2024-07-17T20:09:55.677200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '10'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '10'\n",
    "\n",
    "# Configure TensorFlow session for multi-threading\n",
    "tf.config.threading.set_inter_op_parallelism_threads(10)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(10)\n",
    "# Ensure TensorFlow is using the Metal backend\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "id": "b00dac068399266f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Implementation",
   "id": "7f1a9eb39acea83c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:16:09.498168Z",
     "start_time": "2024-07-18T07:16:09.494245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "\n",
    "print (f\"Python Platform: {platform.platform ()}\")\n",
    "print (f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")\n",
    "print ()\n",
    "\n",
    "print (f\"Python {sys.version}\")\n",
    "print (f\"Pandas {pd.__version__}\")\n",
    "print (f\"Scikit-Learn {sk.__version__}\")\n",
    "print (f\"SciPy {sp.__version__}\")\n",
    "gpu = len (tf.config.list_physical_devices ('GPU'))>0\n",
    "print (\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")\n"
   ],
   "id": "9c40d616696be4c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-14.5-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.16.2\n",
      "Keras Version: 3.4.1\n",
      "\n",
      "Python 3.10.13 (main, Sep 11 2023, 08:16:02) [Clang 14.0.6 ]\n",
      "Pandas 2.2.2\n",
      "Scikit-Learn 1.5.1\n",
      "SciPy 1.10.1\n",
      "GPU is available\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:16:10.263747Z",
     "start_time": "2024-07-18T07:16:10.041264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/filtered_structured_data.csv')\n",
    "print(len(df))\n",
    "df.head()"
   ],
   "id": "c2826091ef289a58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   patientid   sex   age                                                ANA  \\\n",
       "0       61.0  male  32.0  Beschwerden re. Achillessehne. NMR unauffällig...   \n",
       "1       67.0  male  41.0  Seit mehreren Monaten Beschwerden re. Achilles...   \n",
       "2       72.0  male  19.0  . .Gestern beim Training stechende Schmerzen l...   \n",
       "3       72.0  male  23.0  beide Knie Schmerzen bei Treppe steigen oder L...   \n",
       "4       84.0  male  57.0  (08.19 Uhr); bewegungsabhängig.Schmerzen wiede...   \n",
       "\n",
       "                                                 EXA  \\\n",
       "0  Re. Achillessehne: Verdickung im Bereich der A...   \n",
       "1  Re. Achillessehne: Deutliche Auftreibung der A...   \n",
       "2  Klinischer Befund des Oberschenkels li.deutl.V...   \n",
       "3  bd. Knie: frei Bewegl.; Patella o.B.; keine MZ...   \n",
       "4  Klinischer Befund des Kniegelenks li.: Drucksc...   \n",
       "\n",
       "                                            DIA_text  DIA_code OP_text OP_code  \n",
       "0  Retropatellare Chondromalazie li; Insertionste...   M22.4 G     NaN     NaN  \n",
       "1  V.a.laterale Chondromalazie bei st.n. Außenmen...  M23.3- V     NaN     NaN  \n",
       "2   Z.n.arthroskopischer Chirurgie des Kniegelenkes.  M23.3- Z     NaN     NaN  \n",
       "3                           Z.n.IM-Teilresektion re.   S83.2 Z     NaN     NaN  \n",
       "4       Beginnende Gonarthrose bds. li. mehr als re.    M17.9      NaN     NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientid</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ANA</th>\n",
       "      <th>EXA</th>\n",
       "      <th>DIA_text</th>\n",
       "      <th>DIA_code</th>\n",
       "      <th>OP_text</th>\n",
       "      <th>OP_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61.0</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Beschwerden re. Achillessehne. NMR unauffällig...</td>\n",
       "      <td>Re. Achillessehne: Verdickung im Bereich der A...</td>\n",
       "      <td>Retropatellare Chondromalazie li; Insertionste...</td>\n",
       "      <td>M22.4 G</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Seit mehreren Monaten Beschwerden re. Achilles...</td>\n",
       "      <td>Re. Achillessehne: Deutliche Auftreibung der A...</td>\n",
       "      <td>V.a.laterale Chondromalazie bei st.n. Außenmen...</td>\n",
       "      <td>M23.3- V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72.0</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>. .Gestern beim Training stechende Schmerzen l...</td>\n",
       "      <td>Klinischer Befund des Oberschenkels li.deutl.V...</td>\n",
       "      <td>Z.n.arthroskopischer Chirurgie des Kniegelenkes.</td>\n",
       "      <td>M23.3- Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72.0</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>beide Knie Schmerzen bei Treppe steigen oder L...</td>\n",
       "      <td>bd. Knie: frei Bewegl.; Patella o.B.; keine MZ...</td>\n",
       "      <td>Z.n.IM-Teilresektion re.</td>\n",
       "      <td>S83.2 Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>male</td>\n",
       "      <td>57.0</td>\n",
       "      <td>(08.19 Uhr); bewegungsabhängig.Schmerzen wiede...</td>\n",
       "      <td>Klinischer Befund des Kniegelenks li.: Drucksc...</td>\n",
       "      <td>Beginnende Gonarthrose bds. li. mehr als re.</td>\n",
       "      <td>M17.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:16:14.448422Z",
     "start_time": "2024-07-18T07:16:14.088357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "cols = ['ANA', 'EXA', 'age', 'sex']\n",
    "df['data'] = df[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "df['data'].head()\n",
    "texts = df['data']\n",
    "labels = df['DIA_code'].str[:5].to_frame()\n",
    "label_counts = labels.value_counts()\n",
    "encoder = OneHotEncoder()\n",
    "labels = encoder.fit_transform(labels).toarray()\n",
    "num_classes = len(encoder.categories_[0])\n",
    "print(len(df))\n",
    "# Count the occurrences of each label\n",
    "\n",
    "# Plot the distribution of labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_counts.plot(kind='bar')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ],
   "id": "c50cf41aa4b546ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:01:41.609082Z",
     "start_time": "2024-07-17T18:01:36.878510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Tokenize the texts\n",
    "max_length = 400  # Length of input sequences\n",
    "vocab_size = 10000\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=len(word_index), output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, return_sequences=True)(embedding)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(lstm_units)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the mod\n",
    "print(tf.keras.utils.plot_model(model))\n",
    "model.summary()"
   ],
   "id": "240184416e153ac3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001B[38;5;33mInputLayer\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m400\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m400\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │    \u001B[38;5;34m16,243,500\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m400\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │       \u001B[38;5;34m219,648\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m400\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m33\u001B[0m)             │         \u001B[38;5;34m4,257\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,243,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m16,598,989\u001B[0m (63.32 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,598,989</span> (63.32 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m16,598,989\u001B[0m (63.32 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,598,989</span> (63.32 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:17:21.275198Z",
     "start_time": "2024-07-17T18:01:44.297129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model.fit(padded_sequences, labels, epochs=10, batch_size=32, validation_split=0.2)"
   ],
   "id": "699d72a5d33e06fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m90s\u001B[0m 79ms/step - accuracy: 0.3738 - loss: 2.4070 - val_accuracy: 0.3920 - val_loss: 2.2915\n",
      "Epoch 2/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m87s\u001B[0m 77ms/step - accuracy: 0.3838 - loss: 2.3074 - val_accuracy: 0.3920 - val_loss: 2.2935\n",
      "Epoch 3/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m91s\u001B[0m 81ms/step - accuracy: 0.3877 - loss: 2.2984 - val_accuracy: 0.3920 - val_loss: 2.2808\n",
      "Epoch 4/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m88s\u001B[0m 78ms/step - accuracy: 0.3878 - loss: 2.2938 - val_accuracy: 0.3920 - val_loss: 2.2968\n",
      "Epoch 5/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m88s\u001B[0m 78ms/step - accuracy: 0.3862 - loss: 2.2963 - val_accuracy: 0.3920 - val_loss: 2.2931\n",
      "Epoch 6/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m109s\u001B[0m 96ms/step - accuracy: 0.3810 - loss: 2.3011 - val_accuracy: 0.3920 - val_loss: 2.2807\n",
      "Epoch 7/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m121s\u001B[0m 107ms/step - accuracy: 0.3791 - loss: 2.3069 - val_accuracy: 0.3920 - val_loss: 2.2941\n",
      "Epoch 8/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m88s\u001B[0m 78ms/step - accuracy: 0.3796 - loss: 2.3029 - val_accuracy: 0.3920 - val_loss: 2.2999\n",
      "Epoch 9/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m86s\u001B[0m 76ms/step - accuracy: 0.3789 - loss: 2.3683 - val_accuracy: 0.3920 - val_loss: 2.2949\n",
      "Epoch 10/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m88s\u001B[0m 78ms/step - accuracy: 0.3834 - loss: 2.2979 - val_accuracy: 0.3920 - val_loss: 2.3041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3981b71c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Embeddings",
   "id": "d1eef0a01124d6dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Word2Vec",
   "id": "49b8701a82ac6ebd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:36:46.061212Z",
     "start_time": "2024-07-17T18:24:25.622291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-ZäöüÄÖÜß\\s]', '', text)\n",
    "    doc = nlp(text)\n",
    "    stop_words = spacy.lang.de.stop_words.STOP_WORDS\n",
    "    words = [token.text for token in doc if token.text.lower() not in stop_words and token.is_alpha]\n",
    "    return words\n",
    "\n",
    "def get_word2vec_embeddings(text, model, vector_size=300):\n",
    "    tokens = preprocess_text(text)\n",
    "    embeddings = np.zeros((len(tokens), vector_size))\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in model.wv:\n",
    "            embeddings[i] = model.wv[token]\n",
    "        else:\n",
    "            embeddings[i] = np.zeros(vector_size)\n",
    "    return embeddings\n",
    "\n",
    "# Load pre-trained Word2Vec embeddings\n",
    "w2v = Word2Vec.load(\"../data/word2vec.model\")\n",
    "\n",
    "# Convert texts to embeddings\n",
    "word2vec_embeddings = [get_word2vec_embeddings(text, w2v) for text in texts]\n",
    "padded_embeddings = pad_sequences(word2vec_embeddings, padding='post', dtype='float32')\n",
    "\n",
    "# Determine the max length of the sequences\n",
    "max_length = padded_embeddings.shape[1]\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the Word2Vec embeddings\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length, embedding_dim), dtype='float32', name='text_input')\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, return_sequences=True)(input_text)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(lstm_units)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model_word2vec = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model_word2vec.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model_word2vec.summary()"
   ],
   "id": "c32a761593ece509",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 20:36:45.826642: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2024-07-17 20:36:45.826699: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-07-17 20:36:45.826712: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-07-17 20:36:45.826745: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-07-17 20:36:45.826763: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_input (\u001B[38;5;33mInputLayer\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m208\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m208\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │       \u001B[38;5;34m219,648\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m208\u001B[0m, \u001B[38;5;34m128\u001B[0m)       │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m33\u001B[0m)             │         \u001B[38;5;34m4,257\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m355,489\u001B[0m (1.36 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355,489</span> (1.36 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m355,489\u001B[0m (1.36 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">355,489</span> (1.36 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T18:44:40.507111Z",
     "start_time": "2024-07-17T18:36:46.062260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model_word2vec.fit(padded_embeddings, labels, epochs=10, batch_size=32, validation_split=0.2)"
   ],
   "id": "cc83f745466dc78c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 20:36:57.335163: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m49s\u001B[0m 42ms/step - accuracy: 0.3747 - loss: 2.3998 - val_accuracy: 0.3920 - val_loss: 2.3329\n",
      "Epoch 2/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3888 - loss: 2.2967 - val_accuracy: 0.3920 - val_loss: 2.3102\n",
      "Epoch 3/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3771 - loss: 2.3114 - val_accuracy: 0.3920 - val_loss: 2.3022\n",
      "Epoch 4/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3825 - loss: 2.2978 - val_accuracy: 0.3920 - val_loss: 2.2963\n",
      "Epoch 5/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3816 - loss: 2.3063 - val_accuracy: 0.3920 - val_loss: 2.2964\n",
      "Epoch 6/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3853 - loss: 2.2882 - val_accuracy: 0.3920 - val_loss: 2.3036\n",
      "Epoch 7/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3838 - loss: 2.2874 - val_accuracy: 0.3920 - val_loss: 2.2996\n",
      "Epoch 8/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 41ms/step - accuracy: 0.3790 - loss: 2.3044 - val_accuracy: 0.3920 - val_loss: 2.2964\n",
      "Epoch 9/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 40ms/step - accuracy: 0.3864 - loss: 2.2896 - val_accuracy: 0.3920 - val_loss: 2.2987\n",
      "Epoch 10/10\n",
      "\u001B[1m1132/1132\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 40ms/step - accuracy: 0.3823 - loss: 2.3775 - val_accuracy: 0.3920 - val_loss: 2.2912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3a04e95d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bert",
   "id": "7b5eeac98007cfd3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T20:05:55.399864Z",
     "start_time": "2024-07-17T18:48:36.166662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# Function to generate word embeddings for a given text\n",
    "def generate_bert_embeddings(text, tokenizer, model):\n",
    "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True)\n",
    "    outputs = model(inputs)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    return embeddings\n",
    "\n",
    "model_name = \"GerMedBERT/medbert-512\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertModel.from_pretrained(model_name)\n",
    "\n",
    "bert_embeddings = [generate_bert_embeddings(text, tokenizer, model).numpy().squeeze(0) for text in texts]\n",
    "padded_embeddings = pad_sequences(bert_embeddings, padding='post', dtype='float32')\n",
    "\n",
    "\n",
    "# Define model parameters\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "embedding_dim = padded_embeddings.shape[-1]\n",
    "\n",
    "# Define the input layers\n",
    "input_text = Input(shape=(padded_embeddings.shape[1], embedding_dim), dtype='float32', name='text_input')\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, return_sequences=True)(bert_embeddings)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(lstm_units)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model_bert = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model_bert.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model_bert.summary()"
   ],
   "id": "590d28cb82a9c8f4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'bert.embeddings.position_ids', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/4_/5vc_xrv55mjf8lnnrnlx1vz40000gn/T/ipykernel_7885/3357300935.py\u001B[0m in \u001B[0;36m?\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mmodel_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"GerMedBERT/medbert-512\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBertTokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTFBertModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_pretrained\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0mbert_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mgenerate_bert_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtexts\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0mpadded_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpad_sequences\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbert_embeddings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'post'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'float32'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/4_/5vc_xrv55mjf8lnnrnlx1vz40000gn/T/ipykernel_7885/3357300935.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(.0)\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0;32mdef\u001B[0m \u001B[0mgenerate_bert_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tf\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtruncation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlast_hidden_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/4_/5vc_xrv55mjf8lnnrnlx1vz40000gn/T/ipykernel_7885/3357300935.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(text, tokenizer, model)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mgenerate_bert_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"tf\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtruncation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m     \u001B[0membeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlast_hidden_state\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/training.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    584\u001B[0m                 \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mcopied_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcopied_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    586\u001B[0m             \u001B[0mlayout_map_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_subclass_model_variable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_layout_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 588\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    433\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0mconfig\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    436\u001B[0m         \u001B[0munpacked_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_processing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfn_args_and_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 437\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munpacked_inputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[1;32m   1205\u001B[0m         \u001B[0muse_cache\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0mbool\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0moptional\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1206\u001B[0m             If set to `True`, `past_key_values` key value states are returned and can be used to speed up decoding (see\n\u001B[1;32m   1207\u001B[0m             `past_key_values`). Set to `False` during training, `True` during generation\n\u001B[1;32m   1208\u001B[0m         \"\"\"\n\u001B[0;32m-> 1209\u001B[0;31m         outputs = self.bert(\n\u001B[0m\u001B[1;32m   1210\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1211\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1212\u001B[0m             \u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/modeling_tf_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    433\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0mconfig\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    436\u001B[0m         \u001B[0munpacked_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minput_processing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mfn_args_and_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 437\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0munpacked_inputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[1;32m    965\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mNotImplementedError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    966\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    967\u001B[0m             \u001B[0mhead_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_hidden_layers\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    968\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 969\u001B[0;31m         encoder_outputs = self.encoder(\n\u001B[0m\u001B[1;32m    970\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0membedding_output\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    971\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mextended_attention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    972\u001B[0m             \u001B[0mhead_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001B[0m\n\u001B[1;32m    605\u001B[0m                 \u001B[0mall_hidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mall_hidden_states\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    607\u001B[0m             \u001B[0mpast_key_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpast_key_values\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpast_key_values\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    608\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 609\u001B[0;31m             layer_outputs = layer_module(\n\u001B[0m\u001B[1;32m    610\u001B[0m                 \u001B[0mhidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    611\u001B[0m                 \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    612\u001B[0m                 \u001B[0mhead_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001B[0m\n\u001B[1;32m    498\u001B[0m         \u001B[0mtraining\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    499\u001B[0m     ) -> Tuple[tf.Tensor]:\n\u001B[1;32m    500\u001B[0m         \u001B[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m         \u001B[0mself_attn_past_key_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpast_key_value\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mpast_key_value\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 502\u001B[0;31m         self_attention_outputs = self.attention(\n\u001B[0m\u001B[1;32m    503\u001B[0m             \u001B[0minput_tensor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    504\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    505\u001B[0m             \u001B[0mhead_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, input_tensor, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions, training)\u001B[0m\n\u001B[1;32m    392\u001B[0m             \u001B[0mpast_key_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpast_key_value\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    393\u001B[0m             \u001B[0moutput_attentions\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_attentions\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    394\u001B[0m             \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    395\u001B[0m         )\n\u001B[0;32m--> 396\u001B[0;31m         attention_output = self.dense_output(\n\u001B[0m\u001B[1;32m    397\u001B[0m             \u001B[0mhidden_states\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself_outputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_tensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    398\u001B[0m         )\n\u001B[1;32m    399\u001B[0m         \u001B[0;31m# add attentions (possibly with past_key_value) if we output them\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/transformers/models/bert/modeling_tf_bert.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, hidden_states, input_tensor, training)\u001B[0m\n\u001B[1;32m    346\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    348\u001B[0m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_states\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 349\u001B[0;31m         \u001B[0mhidden_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLayerNorm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhidden_states\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0minput_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    350\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    351\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mhidden_states\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 72\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/engine/base_layer.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1132\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1133\u001B[0m                 with autocast_variable.enable_auto_cast_variables(\n\u001B[1;32m   1134\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1135\u001B[0m                 ):\n\u001B[0;32m-> 1136\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1137\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1139\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_handle_activity_regularization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m                 \u001B[0mnew_e\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mnew_e\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m             \u001B[0;32mdel\u001B[0m \u001B[0mbound_signature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tf_keras/src/layers/normalization/layer_normalization.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    293\u001B[0m             \u001B[0mscale\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moffset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_broadcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgamma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_broadcast\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbeta\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m             \u001B[0;31m# Compute layer normalization using the batch_normalization\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    296\u001B[0m             \u001B[0;31m# function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 297\u001B[0;31m             outputs = tf.nn.batch_normalization(\n\u001B[0m\u001B[1;32m    298\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m                 \u001B[0mmean\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m                 \u001B[0mvariance\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 155\u001B[0;31m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1258\u001B[0m       \u001B[0;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1260\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1261\u001B[0;31m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1262\u001B[0m         \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1263\u001B[0m         \u001B[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1264\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop_dispatch_handler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/ops/nn_impl.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(x, mean, variance, offset, scale, variance_epsilon, name)\u001B[0m\n\u001B[1;32m   1478\u001B[0m       \u001B[0;34m[\u001B[0m\u001B[0mIoffe\u001B[0m \u001B[0met\u001B[0m \u001B[0mal\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2015\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m//\u001B[0m\u001B[0marxiv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0morg\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mabs\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0;36m1502.03167\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1479\u001B[0m       \u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpdf\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhttp\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m//\u001B[0m\u001B[0mproceedings\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmlr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpress\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mv37\u001B[0m\u001B[0;34m/\u001B[0m\u001B[0mioffe15\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpdf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1480\u001B[0m   \"\"\"\n\u001B[1;32m   1481\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"batchnorm\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmean\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvariance\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moffset\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1482\u001B[0;31m     \u001B[0minv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrsqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvariance\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mvariance_epsilon\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1483\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mscale\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1484\u001B[0m       \u001B[0minv\u001B[0m \u001B[0;34m*=\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1485\u001B[0m     \u001B[0;31m# Note: tensorflow/contrib/quantize/python/fold_batch_norms.py depends on\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 155\u001B[0;31m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/framework/override_binary_operator.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(x, y)\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0;31m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    111\u001B[0m         \u001B[0;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmaybe_promote_tensors\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 114\u001B[0;31m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    115\u001B[0m         \u001B[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;31m# object that can implement the operator with knowledge of itself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m         \u001B[0;31m# and the tensor.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/ops/tensor_math_operator_overrides.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_add_dispatch_factory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m   \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mops\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_add_dispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m       \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 155\u001B[0;31m       \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1258\u001B[0m       \u001B[0;31m# Fallback dispatch system (dispatch v1):\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1259\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1260\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch_target\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1261\u001B[0;31m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1262\u001B[0m         \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1263\u001B[0m         \u001B[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1264\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mop_dispatch_handler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(x, y, name)\u001B[0m\n",
      "\u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf2/lib/python3.10/site-packages/tensorflow/python/ops/gen_math_ops.py\u001B[0m in \u001B[0;36m?\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m    478\u001B[0m         _ctx, \"AddV2\", name, x, y)\n\u001B[1;32m    479\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    480\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    485\u001B[0m       return add_v2_eager_fallback(\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T20:05:55.401202Z",
     "start_time": "2024-07-17T20:05:55.401113Z"
    }
   },
   "cell_type": "code",
   "source": "model_bert.fit(padded_embeddings, labels, epochs=10, batch_size=32, validation_split=0.2)",
   "id": "c994d8a30426bf0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "with open('bert_embeddings.pkl', 'wb') as file: \n",
    "    pickle.dump(padded_embeddings, file) "
   ],
   "id": "5fe4b724c28fff20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Batchnormalization",
   "id": "b9ee737834ef8042"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### On input",
   "id": "bb7a3375df2cedee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Tokenize the texts\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "max_length = 400  # Length of input sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, return_sequences=True)(embedding)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = LSTM(lstm_units)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "print(tf.keras.utils.plot_model(model))\n",
    "model.summary()"
   ],
   "id": "aa4e34ee1ac19951"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regularization",
   "id": "7a1297bc10f22a05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## No regularization",
   "id": "b913b9f3bdad567c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "# Tokenize the texts\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "max_length = 400  # Length of input sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, return_sequences=True)(embedding)\n",
    "x = LSTM(lstm_units)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "print(tf.keras.utils.plot_model(model))\n",
    "model.summary()"
   ],
   "id": "42f1427cf37edbc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## L1 Regularization",
   "id": "9d66a280414be82c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "# Tokenize the texts\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "max_length = 400  # Length of input sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, kernel_regularizer=l1(0.01), return_sequences=True)(embedding)\n",
    "x = LSTM(lstm_units, kernel_regularizer=l1(0.01))(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "print(tf.keras.utils.plot_model(model))\n",
    "model.summary()"
   ],
   "id": "4f96baccac7f9c2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## L2 Regularization",
   "id": "9fc1bbf935edbc50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Tokenize the texts\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "max_length = 400  # Length of input sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, kernel_regularizer=l2(0.01), return_sequences=True)(embedding)\n",
    "x = LSTM(lstm_units, kernel_regularizer=l2(0.01))(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "print(tf.keras.utils.plot_model(model))\n",
    "model.summary()"
   ],
   "id": "40fba3056a89b1bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## L1/L2 Regularization",
   "id": "d229e109f3146527"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Tokenize the texts\n",
    "vocab_size = 10000  # Size of the vocabulary\n",
    "max_length = 400  # Length of input sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Define model parameters\n",
    "embedding_dim = 300  # Dimension of the embedding vectors\n",
    "lstm_units = 128  # Number of LSTM units\n",
    "\n",
    "# Define the input layer\n",
    "input_text = Input(shape=(max_length,), dtype='int32', name='text_input')\n",
    "\n",
    "# Embedding layer\n",
    "embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_text)\n",
    "\n",
    "# Two LSTM layers\n",
    "x = LSTM(lstm_units, kernel_regularizer=l1_l2(l1=0.01, l2=0.01), return_sequences=True)(embedding)\n",
    "x = LSTM(lstm_units, kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "print(tf.keras.utils.plot_model(model))\n",
    "model.summary()"
   ],
   "id": "57e4254ce2d5645"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Input Dropout Regularization",
   "id": "5a86ab50c0a58a25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b36f6c6d2e9adfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reccurent Dropout Regularization",
   "id": "df93847b278f126d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x = LSTM(lstm_units, recurrent_dropout=0.2, return_sequences=False)(x)",
   "id": "4004370cf5b99cbe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
